{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83227418-fb4e-4597-b625-9f8ebaec7514",
   "metadata": {},
   "source": [
    "# Head Pose Estimation\n",
    "### Supervised ML Project\n",
    "- Dataset used: AFLW2000 Dataset to read image and Extraxt landmarks from images.\n",
    "- AFLW2000 conist of 2000 images, download from this link:  \n",
    "http://www.cbsr.ia.ac.cn/users/xiangyuzhu/projects/3DDFA/main.htm\n",
    "\n",
    "- Project Guide: https://github.com/s7s/machine_learning_1/blob/master/ML_in_practice/ProjectHelper.ipynb\n",
    "\n",
    "- In this NoteBook steps we follow:\n",
    "  - Importing & Installing\n",
    "  - Project Helper Test\n",
    "  - Reading Images and Extracting Landmarks from data\n",
    "  - Reading and Preparing the Data\n",
    "  - Machine Learning Models Training\n",
    "  - Reading Trained Models \n",
    "  - Live Camera and Draw axises on face"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3515b94e",
   "metadata": {
    "id": "e1d19fb3-3ff3-46dd-ae35-ac798ef1a684"
   },
   "source": [
    "## Imporing and Installing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0dfb985b-c0d0-4828-a3d9-010ce9eb1e65",
   "metadata": {
    "id": "0dfb985b-c0d0-4828-a3d9-010ce9eb1e65"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "# !pip install mediapipe\n",
    "# !pip install opencv\n",
    "# !pip install scipy\n",
    "# !pip install pathlib\n",
    "# !pip install mediapipe opencv-python pandas scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "373bfae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install protobuf==3.19.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9f4e55f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.9.7\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5482f521-59f3-4d23-b2b6-82546dacd100",
   "metadata": {
    "id": "5482f521-59f3-4d23-b2b6-82546dacd100"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os,cv2,math,glob,random\n",
    "import scipy.io as sio\n",
    "from math import cos, sin\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import mediapipe\n",
    "# import cv2 # Import opencv\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# from google.colab.patches import cv2_imshow\n",
    "import csv\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from math import cos ,sin\n",
    "import pickle \n",
    "\n",
    "### Machine Learning Models\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler, MaxAbsScaler, QuantileTransformer, PowerTransformer, PolynomialFeatures\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge , ridge_regression,Lasso\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, VotingRegressor,BaggingRegressor,ExtraTreesRegressor\n",
    "from sklearn.pipeline import make_pipeline, FeatureUnion\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import GradientBoostingRegressor, AdaBoostRegressor\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler, MaxAbsScaler\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.linear_model import OrthogonalMatchingPursuit\n",
    "from sklearn.datasets import make_regression\n",
    "import sklearn.linear_model\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn import tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "abb47a95-62a6-47a6-8631-8927782708c4",
   "metadata": {
    "id": "abb47a95-62a6-47a6-8631-8927782708c4"
   },
   "outputs": [],
   "source": [
    "mp_drawing = mediapipe.solutions.drawing_utils # Drawing helpers\n",
    "mp_holistic = mediapipe.solutions.holistic # Mediapipe Solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "vTgd5WVKuLlF",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vTgd5WVKuLlF",
    "outputId": "3ef83c9c-13ad-42eb-9b98-5aa2b918aabf"
   },
   "outputs": [],
   "source": [
    "### If working on Dirve\n",
    "\n",
    "\n",
    "# from google.colab import drive\n",
    "# drive.mount(\"/content/drive\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "Ptresh5Mwijc",
   "metadata": {
    "id": "Ptresh5Mwijc"
   },
   "outputs": [],
   "source": [
    "### tracking where is the .zip file exactly on drive\n",
    "\n",
    "# os.chdir(\"/content/drive/\")\n",
    "\n",
    "# os.chdir(\"/content/drive/MyDrive/Data/AFLW2000\")\n",
    "# !ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "XHR4rzwvuPBi",
   "metadata": {
    "id": "XHR4rzwvuPBi"
   },
   "outputs": [],
   "source": [
    "### Extracting the data from the zip file\n",
    "\n",
    "# %%capture\n",
    "# !unzip /content/drive/MyDrive/Data/AFLW2000-3D.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "q2Zid32noALY",
   "metadata": {
    "id": "q2Zid32noALY"
   },
   "outputs": [],
   "source": [
    "### Folder Path \n",
    "\n",
    "# folder_path = \"/content/AFLW2000/\"\n",
    "\n",
    "# folder_path = \"/content/drive/MyDrive/Data/AFLW2000/\"\n",
    "\n",
    "\n",
    "folder_path = \"C:\\\\Users\\\\SIDDIK\\#ITI_Laptop\\#ITI_PC\\ML 1\\PC\\ML 1\\Project\\content\\AFLW2000/\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b23ad58-7671-47c2-9069-298d4304db22",
   "metadata": {},
   "source": [
    "### Project Healper test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "m9JHvNRmcKyF",
   "metadata": {
    "id": "m9JHvNRmcKyF"
   },
   "outputs": [],
   "source": [
    "# def draw_axis(img, pitch,yaw,roll, tdx=None, tdy=None, size = 100):\n",
    "\n",
    "#     yaw = -yaw\n",
    "#     if tdx != None and tdy != None:\n",
    "#         tdx = tdx\n",
    "#         tdy = tdy\n",
    "#     else:\n",
    "#         height, width = img.shape[:2]\n",
    "#         tdx = width / 2\n",
    "#         tdy = height / 2\n",
    "\n",
    "#     # X-Axis pointing to right. drawn in red\n",
    "#     x1 = size * (cos(yaw) * cos(roll)) + tdx\n",
    "#     y1 = size * (cos(pitch) * sin(roll) + cos(roll) * sin(pitch) * sin(yaw)) + tdy\n",
    "\n",
    "#     # Y-Axis | drawn in green\n",
    "#     #        v\n",
    "#     x2 = size * (-cos(yaw) * sin(roll)) + tdx\n",
    "#     y2 = size * (cos(pitch) * cos(roll) - sin(pitch) * sin(yaw) * sin(roll)) + tdy\n",
    "\n",
    "#     # Z-Axis (out of the screen) drawn in blue\n",
    "#     x3 = size * (sin(yaw)) + tdx\n",
    "#     y3 = size * (-cos(yaw) * sin(pitch)) + tdy\n",
    "\n",
    "#     cv2.line(img, (int(tdx), int(tdy)), (int(x1),int(y1)),(0,0,255),3)\n",
    "#     cv2.line(img, (int(tdx), int(tdy)), (int(x2),int(y2)),(0,255,0),3)\n",
    "#     cv2.line(img, (int(tdx), int(tdy)), (int(x3),int(y3)),(255,0,0),2)\n",
    "\n",
    "#     return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fYDFVywGcWdc",
   "metadata": {
    "id": "fYDFVywGcWdc"
   },
   "outputs": [],
   "source": [
    "# # choosing random image\n",
    "# random_file = 'image00053'\n",
    "\n",
    "# faceModule = mediapipe.solutions.face_mesh\n",
    "# # loading image and its correspinding mat file\n",
    "# with faceModule.FaceMesh(static_image_mode=True) as faces:\n",
    "#     # loading the image\n",
    "#     image = cv2.imread('/content/AFLW2000/'+random_file+'.jpg')\n",
    "#     # processing the face to extract the landmark points (468 point) for each x,y,z\n",
    "#     results = faces.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "#     if results.multi_face_landmarks != None: \n",
    "#       # looping over the faces in the image\n",
    "#       for face in results.multi_face_landmarks:\n",
    "#           for landmark in face.landmark:\n",
    "#               x = landmark.x\n",
    "#               y = landmark.y\n",
    "#               # note: the x and y values are scaled to the their width and height so we will get back their actual value in the image\n",
    "#               shape = image.shape \n",
    "#               relative_x = int(x * shape[1])\n",
    "#               relative_y = int(y * shape[0])\n",
    "#               # cv2.putText(image, str(relative_y), (int(relative_x),int(relative_y)), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0,255,0), 2)\n",
    "#               cv2.circle(image, (relative_x, relative_y), radius=1, color=(0, 255, 0), thickness=2)\n",
    "#       cv2_imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba2384f",
   "metadata": {
    "id": "VCXmH9n3vnAt"
   },
   "source": [
    "## Reading Images and Extracting Landmarks from data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "-s-7iPSKcha6",
   "metadata": {
    "id": "-s-7iPSKcha6"
   },
   "outputs": [],
   "source": [
    "### getting the img names in a list\n",
    "\n",
    "def file_names(path):\n",
    "  img_names= []\n",
    "\n",
    "  # Python method listdir() returns a list containing the names of the entries in the directory given by path. The list is in arbitrary order\n",
    "  # we use sorted to sort the img names accending by default\n",
    "  for file_name in sorted(os.listdir(path)):\n",
    "    if file_name.endswith(\".jpg\"):\n",
    "      img_names.append(file_name)\n",
    "  return img_names      \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aOhJzofalKWd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aOhJzofalKWd",
    "outputId": "cce1edb7-192e-407b-f1fd-5a1d47ec8426"
   },
   "outputs": [],
   "source": [
    "### printing the the file names\n",
    "\n",
    "# print(file_names(folder_path))\n",
    "# print(\"Number of imgs: \",len(file_names(folder_path)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5iz5oBzfXdla",
   "metadata": {
    "id": "5iz5oBzfXdla"
   },
   "outputs": [],
   "source": [
    "img_names = file_names(folder_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "XC-BVBHCk-dO",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XC-BVBHCk-dO",
    "outputId": "57a3664f-4e9a-4996-e05d-5b34dac52144"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "C:\\Users\\SIDDIK\\#ITI_Laptop\\#ITI_PC\\ML 1\\PC\\ML 1\\Project\\content\\AFLW2000/image00002.jpg\n",
      "1\n",
      "C:\\Users\\SIDDIK\\#ITI_Laptop\\#ITI_PC\\ML 1\\PC\\ML 1\\Project\\content\\AFLW2000/image00004.jpg\n",
      "2\n",
      "C:\\Users\\SIDDIK\\#ITI_Laptop\\#ITI_PC\\ML 1\\PC\\ML 1\\Project\\content\\AFLW2000/image00006.jpg\n",
      "3\n",
      "C:\\Users\\SIDDIK\\#ITI_Laptop\\#ITI_PC\\ML 1\\PC\\ML 1\\Project\\content\\AFLW2000/image00008.jpg\n",
      "4\n",
      "C:\\Users\\SIDDIK\\#ITI_Laptop\\#ITI_PC\\ML 1\\PC\\ML 1\\Project\\content\\AFLW2000/image00010.jpg\n",
      "5\n",
      "C:\\Users\\SIDDIK\\#ITI_Laptop\\#ITI_PC\\ML 1\\PC\\ML 1\\Project\\content\\AFLW2000/image00013.jpg\n"
     ]
    }
   ],
   "source": [
    "### Testing: every file has an index and a path\n",
    "\n",
    "# for idx, file in enumerate(folder_path + s for s in img_names):\n",
    "#   print(idx)\n",
    "#   print(file)\n",
    "\n",
    "#   if idx == 5:\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "y0ftofYvlKbl",
   "metadata": {
    "id": "y0ftofYvlKbl"
   },
   "outputs": [],
   "source": [
    "### Testing: Getting face_landmarks from Imges\n",
    "\n",
    "def face_landmarks(folder_path,img_names):\n",
    "\n",
    "    with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "        \n",
    "        for idx, file in enumerate(folder_path + s for s in img_names):\n",
    "\n",
    "            image = cv2.imread(file)\n",
    "            image_height, image_width, _ = image.shape        \n",
    "\n",
    "            \n",
    "## Convert the BGR image to RGB before processing.\n",
    "\n",
    "            results = holistic.process(cv2.cvtColor(image, cv2.COLOR_RGB2BGR))\n",
    "    #         results = holistic.process(image)\n",
    "    #         print(results.face_landmarks)\n",
    "            # 1. Draw face landmarks\n",
    "            mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACEMESH_TESSELATION, \n",
    "                                    mp_drawing.DrawingSpec(color=(80,110,10), thickness=1, circle_radius=1),\n",
    "                                    mp_drawing.DrawingSpec(color=(80,256,121), thickness=1, circle_radius=1)\n",
    "                                    )\n",
    "            \n",
    "            break\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "Ccns1T8Ma0l3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ccns1T8Ma0l3",
    "outputId": "077ce656-f8b2-4a9a-ab5d-0e0567483636"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "x: 0.47754186391830444\n",
       "y: 0.6920552253723145\n",
       "z: -0.018991734832525253"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = face_landmarks(folder_path,img_names)\n",
    "\n",
    "results.face_landmarks.landmark[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fAH8FpOXZSnt",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fAH8FpOXZSnt",
    "outputId": "ccb147ad-2f0d-4b9f-c3d0-cdc95f989514"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "468"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_coords = len(results.face_landmarks.landmark)\n",
    "num_coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "Lih0soS3m9fL",
   "metadata": {
    "id": "Lih0soS3m9fL"
   },
   "outputs": [],
   "source": [
    "### making a header row for the csv file\n",
    "\n",
    "landmarks = []\n",
    "\n",
    "for val in range(1, num_coords+1):\n",
    "    landmarks += ['x{}'.format(val), 'y{}'.format(val)]\n",
    "# landmarks\n",
    "labels=['pitch','yaw','roll']\n",
    "data = landmarks+labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8V2CEV7SnzUJ",
   "metadata": {
    "id": "8V2CEV7SnzUJ"
   },
   "outputs": [],
   "source": [
    "### creating a csv file and adding the header row\n",
    "\n",
    "with open(\"C:\\\\Users\\\\SIDDIK\\#ITI_Laptop\\#ITI_PC\\ML 1\\PC\\ML 1\\Project\\content/\" +'landmarks_data.csv', mode='w', newline='') as f:\n",
    "    csv_writer = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "    csv_writer.writerow(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7046add5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### testing the access to mat files\n",
    "\n",
    "\n",
    "# img_names_without_jpg= [name.replace('.jpg' , '') for name in img_names]\n",
    "\n",
    "# mat_file = sio.loadmat(  folder_path + img_names_without_jpg[0] + '.mat')\n",
    "\n",
    "# pose_para = mat_file[\"Pose_Para\"][0][:3]\n",
    "\n",
    "# # print(mat_file)\n",
    "# print(pose_para)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "wHI499Ol_s6u",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "wHI499Ol_s6u",
    "outputId": "e00bb467-10da-4f90-b6e8-7e09b65f497f"
   },
   "outputs": [],
   "source": [
    "img_names_without_jpg= [name.replace('.jpg' , '') for name in img_names]\n",
    "# img_names_without_jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "pkaX4wWEoZWE",
   "metadata": {
    "id": "pkaX4wWEoZWE"
   },
   "outputs": [],
   "source": [
    "# ## variables: folder_path, img_names \n",
    "\n",
    "### Appending the data from mat file to the CSV\n",
    "\n",
    "def append_CSV(folder_path,img_names):\n",
    "    \n",
    "    # img_names_without_jpg= [name.replace('.jpg' , '') for name in img_names]\n",
    "\n",
    "    with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    \n",
    "      for idx, file in enumerate(folder_path + s for s in img_names):\n",
    "        image = cv2.imread(file)\n",
    "        image_height, image_width, _ = image.shape\n",
    "    #         Convert the BGR image to RGB before processing.\n",
    "        results = holistic.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "        try:\n",
    "            ### Normilzation and Centerization\n",
    "            \n",
    "            face = results.face_landmarks.landmark\n",
    "            NoseX = results.pose_landmarks.landmark[mp_holistic.PoseLandmark.NOSE].x * image_width        \n",
    "            NoseY=results.pose_landmarks.landmark[mp_holistic.PoseLandmark.NOSE].y   *image_height\n",
    "            LfeoX = results.pose_landmarks.landmark[mp_holistic.PoseLandmark.LEFT_EYE_OUTER].x *image_width\n",
    "            LfeoY = results.pose_landmarks.landmark[mp_holistic.PoseLandmark.LEFT_EYE_OUTER].y* image_height\n",
    "            dist = math.dist([NoseX, NoseY], [LfeoX, LfeoY])\n",
    "\n",
    "\n",
    "            face_row = list(np.array([[   ((landmark.x *image_width)-NoseX)/dist, \n",
    "                                                    ((landmark.y*image_height)-NoseY)/dist] for landmark in face]).flatten())\n",
    "\n",
    "\n",
    "            mat_file = sio.loadmat(  folder_path + img_names_without_jpg[idx] + '.mat')\n",
    "\n",
    "        #       print(mat_file)\n",
    "\n",
    "            pose_para = mat_file[\"Pose_Para\"][0][:3]\n",
    "            pitch = pose_para[0]\n",
    "            yaw = pose_para[1]\n",
    "            roll = pose_para[2]\n",
    "            face_row.insert(((468*2)+0),pitch)\n",
    "            face_row.insert(((468*2)+1),yaw)\n",
    "            face_row.insert(((468*2)+2),roll)\n",
    "\n",
    "            with open('C:\\\\Users\\\\SIDDIK\\#ITI_Laptop\\#ITI_PC\\ML 1\\PC\\ML 1\\Project\\content/' + 'landmarks_data.csv', mode='a', newline='') as f:\n",
    "                csv_writer = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "                csv_writer.writerow(face_row)\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0e936442",
   "metadata": {},
   "outputs": [],
   "source": [
    "append_CSV(folder_path,img_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Lq0-ExmFP9Ms",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Lq0-ExmFP9Ms",
    "outputId": "2aaf3231-41fa-485e-a18f-45e0a60cb192"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "899d4c00",
   "metadata": {
    "id": "yGPVNS9CQjfr"
   },
   "source": [
    "## Reading and Preparing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "M84uEbErNsFp",
   "metadata": {
    "id": "M84uEbErNsFp"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>y1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y2</th>\n",
       "      <th>x3</th>\n",
       "      <th>y3</th>\n",
       "      <th>x4</th>\n",
       "      <th>y4</th>\n",
       "      <th>x5</th>\n",
       "      <th>y5</th>\n",
       "      <th>...</th>\n",
       "      <th>y465</th>\n",
       "      <th>x466</th>\n",
       "      <th>y466</th>\n",
       "      <th>x467</th>\n",
       "      <th>y467</th>\n",
       "      <th>x468</th>\n",
       "      <th>y468</th>\n",
       "      <th>pitch</th>\n",
       "      <th>yaw</th>\n",
       "      <th>roll</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.159295</td>\n",
       "      <td>0.300003</td>\n",
       "      <td>-0.169120</td>\n",
       "      <td>0.067671</td>\n",
       "      <td>-0.146352</td>\n",
       "      <td>0.109180</td>\n",
       "      <td>-0.190952</td>\n",
       "      <td>-0.301066</td>\n",
       "      <td>-0.161892</td>\n",
       "      <td>-0.022124</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.640003</td>\n",
       "      <td>0.132219</td>\n",
       "      <td>-0.604989</td>\n",
       "      <td>0.751723</td>\n",
       "      <td>-0.761274</td>\n",
       "      <td>0.807323</td>\n",
       "      <td>-0.806983</td>\n",
       "      <td>-0.399231</td>\n",
       "      <td>0.018227</td>\n",
       "      <td>0.085676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.334478</td>\n",
       "      <td>0.261430</td>\n",
       "      <td>-0.472663</td>\n",
       "      <td>-0.051103</td>\n",
       "      <td>-0.284650</td>\n",
       "      <td>0.053159</td>\n",
       "      <td>-0.358159</td>\n",
       "      <td>-0.332285</td>\n",
       "      <td>-0.480441</td>\n",
       "      <td>-0.137888</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.525273</td>\n",
       "      <td>0.037087</td>\n",
       "      <td>-0.505745</td>\n",
       "      <td>0.562256</td>\n",
       "      <td>-0.565438</td>\n",
       "      <td>0.632099</td>\n",
       "      <td>-0.617696</td>\n",
       "      <td>0.470065</td>\n",
       "      <td>1.189533</td>\n",
       "      <td>0.300959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.981481</td>\n",
       "      <td>1.076963</td>\n",
       "      <td>-0.956155</td>\n",
       "      <td>0.954189</td>\n",
       "      <td>-0.976846</td>\n",
       "      <td>0.985318</td>\n",
       "      <td>-1.013231</td>\n",
       "      <td>0.778098</td>\n",
       "      <td>-0.954629</td>\n",
       "      <td>0.903266</td>\n",
       "      <td>...</td>\n",
       "      <td>0.634062</td>\n",
       "      <td>-0.919076</td>\n",
       "      <td>0.647000</td>\n",
       "      <td>-0.675460</td>\n",
       "      <td>0.588512</td>\n",
       "      <td>-0.651586</td>\n",
       "      <td>0.567591</td>\n",
       "      <td>-0.184650</td>\n",
       "      <td>0.881137</td>\n",
       "      <td>-0.236852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.127447</td>\n",
       "      <td>0.433119</td>\n",
       "      <td>-0.086203</td>\n",
       "      <td>0.200610</td>\n",
       "      <td>0.035008</td>\n",
       "      <td>0.228611</td>\n",
       "      <td>-0.239562</td>\n",
       "      <td>-0.172509</td>\n",
       "      <td>-0.133581</td>\n",
       "      <td>0.104239</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.642603</td>\n",
       "      <td>0.021166</td>\n",
       "      <td>-0.595805</td>\n",
       "      <td>0.629668</td>\n",
       "      <td>-0.972822</td>\n",
       "      <td>0.673793</td>\n",
       "      <td>-1.040024</td>\n",
       "      <td>-0.175379</td>\n",
       "      <td>0.299208</td>\n",
       "      <td>-0.373374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.078761</td>\n",
       "      <td>0.400796</td>\n",
       "      <td>-0.344684</td>\n",
       "      <td>0.090758</td>\n",
       "      <td>-0.104594</td>\n",
       "      <td>0.147864</td>\n",
       "      <td>-0.317465</td>\n",
       "      <td>-0.235742</td>\n",
       "      <td>-0.383646</td>\n",
       "      <td>-0.000681</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.595326</td>\n",
       "      <td>-0.004369</td>\n",
       "      <td>-0.552671</td>\n",
       "      <td>0.427108</td>\n",
       "      <td>-0.790101</td>\n",
       "      <td>0.482372</td>\n",
       "      <td>-0.853066</td>\n",
       "      <td>-0.882169</td>\n",
       "      <td>1.198003</td>\n",
       "      <td>-1.033374</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 939 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         x1        y1        x2        y2        x3        y3        x4  \\\n",
       "0 -0.159295  0.300003 -0.169120  0.067671 -0.146352  0.109180 -0.190952   \n",
       "1 -0.334478  0.261430 -0.472663 -0.051103 -0.284650  0.053159 -0.358159   \n",
       "2 -0.981481  1.076963 -0.956155  0.954189 -0.976846  0.985318 -1.013231   \n",
       "3  0.127447  0.433119 -0.086203  0.200610  0.035008  0.228611 -0.239562   \n",
       "4 -0.078761  0.400796 -0.344684  0.090758 -0.104594  0.147864 -0.317465   \n",
       "\n",
       "         y4        x5        y5  ...      y465      x466      y466      x467  \\\n",
       "0 -0.301066 -0.161892 -0.022124  ... -0.640003  0.132219 -0.604989  0.751723   \n",
       "1 -0.332285 -0.480441 -0.137888  ... -0.525273  0.037087 -0.505745  0.562256   \n",
       "2  0.778098 -0.954629  0.903266  ...  0.634062 -0.919076  0.647000 -0.675460   \n",
       "3 -0.172509 -0.133581  0.104239  ... -0.642603  0.021166 -0.595805  0.629668   \n",
       "4 -0.235742 -0.383646 -0.000681  ... -0.595326 -0.004369 -0.552671  0.427108   \n",
       "\n",
       "       y467      x468      y468     pitch       yaw      roll  \n",
       "0 -0.761274  0.807323 -0.806983 -0.399231  0.018227  0.085676  \n",
       "1 -0.565438  0.632099 -0.617696  0.470065  1.189533  0.300959  \n",
       "2  0.588512 -0.651586  0.567591 -0.184650  0.881137 -0.236852  \n",
       "3 -0.972822  0.673793 -1.040024 -0.175379  0.299208 -0.373374  \n",
       "4 -0.790101  0.482372 -0.853066 -0.882169  1.198003 -1.033374  \n",
       "\n",
       "[5 rows x 939 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('C:\\\\Users\\\\SIDDIK\\#ITI_Laptop\\#ITI_PC\\ML 1\\PC\\ML 1\\Project\\content/' + 'landmarks_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6DDMdEKfR0JR",
   "metadata": {
    "id": "6DDMdEKfR0JR"
   },
   "outputs": [],
   "source": [
    "#Features\n",
    "x=df.drop(['pitch','yaw','roll'], axis=1)\n",
    "#Pitch label\n",
    "yp=df['pitch']\n",
    "#Yaw label\n",
    "yy=df['yaw']\n",
    "#roll label\n",
    "yr=df['roll']\n",
    "#labels\n",
    "yall =df[['pitch','yaw','roll']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00515dc6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aa6caf76",
   "metadata": {},
   "source": [
    "#### Dividing into Train, Validation, Test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "F6D77nV91FSf",
   "metadata": {
    "id": "F6D77nV91FSf"
   },
   "outputs": [],
   "source": [
    "### PITCH \n",
    "\n",
    "X_train_p, X_val_p, y_train_p, y_val_p = train_test_split(x, yp, test_size=0.2,shuffle=True, random_state=1234)\n",
    "\n",
    "X_val_p, X_test_p, y_val_p, y_test_p = train_test_split(X_val_p, y_val_p, test_size=0.5,shuffle=True, random_state=1234)\n",
    "\n",
    "\n",
    "### YAW \n",
    "\n",
    "X_train_y, X_val_y, y_train_y, y_val_y = train_test_split(x, yy, test_size=0.2, shuffle=True,random_state=1234)\n",
    "\n",
    "X_val_y, X_test_y, y_val_y, y_test_y = train_test_split(X_val_y, y_val_y, test_size=0.5, shuffle=True,random_state=1234)\n",
    "\n",
    "\n",
    "### Roll \n",
    "\n",
    "X_train_r, X_val_r, y_train_r, y_val_r = train_test_split(x, yr, test_size=0.2,shuffle=True, random_state=1234)\n",
    "\n",
    "X_val_r, X_test_r, y_val_r, y_test_r = train_test_split(X_val_r, y_val_r, test_size=0.5,shuffle=True, random_state=1234)\n",
    "\n",
    "\n",
    "### ALL \n",
    "\n",
    "\n",
    "X_train_all, X_val_all, y_train_all, y_val_all = train_test_split(x, yall, test_size=0.2,shuffle=True, random_state=1234)\n",
    "\n",
    "X_val_all, X_test_all, y_val_all, y_test_all = train_test_split(X_val_all, y_val_all, test_size=0.5,shuffle=True, random_state=1234)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6cb4681",
   "metadata": {
    "id": "vzRuCfs89nVc"
   },
   "source": [
    "## Machine Learning Models Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8811ea97",
   "metadata": {
    "id": "a5cmphI61FZw"
   },
   "source": [
    "#### YAW Data (Training, Error & Score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0da614a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Creating a pipleline for different ML models to Test\n",
    "\n",
    "pipelines = {\n",
    "#     'lr_pca':make_pipeline(StandardScaler(),PCA(n_components=0.99), LinearRegression()),\n",
    "    'rf_pca':make_pipeline(StandardScaler(),PCA(n_components=0.99), RandomForestRegressor())\n",
    "#     ,'lr_wpca':make_pipeline(PCA(n_components=0.99),LinearRegression()),\n",
    "#     'rf_wpca':make_pipeline(PCA(n_components=0.99),RandomForestRegressor()),\n",
    "#     'DT'    :make_pipeline(DecisionTreeRegressor()),\n",
    "#     'DTpca' :make_pipeline(PCA(n_components=0.99),DecisionTreeRegressor()),\n",
    "#     'rfpcap' :make_pipeline(   RandomForestRegressor(n_estimators=30, n_jobs=-1))\n",
    "# \n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266e9424",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "438218c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### building a dict to store the model name as a key and the pipeline.fit() as a value\n",
    "\n",
    "yaw_fit_models = {}\n",
    "for algo, pipeline in pipelines.items():\n",
    "    model = pipeline.fit(X_train_y, y_train_y)\n",
    "    yaw_fit_models[algo] = model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "05849b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_pred_yaw      = yaw_fit_models['rf_pca'].predict(X_train_y)\n",
    "Validation_pred_yaw = yaw_fit_models['rf_pca'].predict(X_val_y)\n",
    "yaw_hat = yaw_fit_models['rf_pca'].predict(X_test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e95a3e65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train MSE  0.009360596924033375\n",
      "Validation MSE  0.020722013460169934\n",
      "\n",
      "\n",
      "\n",
      "Train r2_score  97.19705052037374 %\n",
      "Validation r2_score  94.04912024806688 %\n",
      "Test r2_score  93.34677486087985 %\n",
      "\n",
      "\n",
      "\n",
      "Train score  97.19705052037374 %\n",
      "Validation Score  94.04912024806688 %\n",
      "test score:  93.34677486087985 %\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Checking the Score of the model\n",
    "\n",
    "print(\"Train MSE \"       , mean_squared_error( y_train_y,Train_pred_yaw ))\n",
    "print(\"Validation MSE \"  , mean_squared_error( y_val_y,Validation_pred_yaw ))\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "\n",
    "print(\"Train r2_score \"            , r2_score(y_train_y,Train_pred_yaw)*100,\"%\")\n",
    "print(\"Validation r2_score \"       , r2_score( y_val_y, Validation_pred_yaw)*100,\"%\")\n",
    "print(\"Test r2_score \"             , r2_score(y_test_y , yaw_hat)*100,\"%\")\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "\n",
    "print(\"Train score \"                   , yaw_fit_models['rf_pca'].score(X_train_y , y_train_y)*100,\"%\")\n",
    "print(\"Validation Score \"              , yaw_fit_models['rf_pca'].score(X_val_y, y_val_y)*100,\"%\")\n",
    "print(\"test score: \"                   ,yaw_fit_models ['rf_pca'].score(X_test_y, y_test_y)*100,\"%\")\n",
    "print(\"\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8ba548c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Writing results To a pickle file\n",
    "\n",
    "with open(\"C:\\\\Users\\\\SIDDIK\\#ITI_Laptop\\#ITI_PC\\ML 1\\PC\\ML 1\\Project\\content/\"+'yaw_model.pkl', 'wb') as f:\n",
    "    pickle.dump(yaw_fit_models ['rf_pca'], f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccdaaaec",
   "metadata": {},
   "source": [
    "### ROLL Data (Training, Error & Score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4675c53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Creating a pipleline for different ML models to Test\n",
    "\n",
    "pipelines = {\n",
    "#     'rf_pca':make_pipeline(StandardScaler(),PCA(n_components=0.99), RandomForestRegressor()),\n",
    "#     'DTpca' :make_pipeline(PCA(n_components=0.99),DecisionTreeRegressor()),\n",
    "    'rfpcap' :make_pipeline(PCA(n_components=0.99), RandomForestRegressor(n_estimators=200)),\n",
    "\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "99830819",
   "metadata": {},
   "outputs": [],
   "source": [
    "roll_fit_models = {}\n",
    "for algo, pipeline in pipelines.items():\n",
    "    model = pipeline.fit(X_train_r, y_train_r)\n",
    "    roll_fit_models[algo] = model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6e2c8039",
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_pred_roll     = roll_fit_models  ['rfpcap'].predict(X_train_r)\n",
    "Validation_pred_roll = roll_fit_models ['rfpcap'].predict(X_val_r)\n",
    "roll_hat             =roll_fit_models  ['rfpcap'].predict(X_test_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "dd630dea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train MSE  0.060134276097569266\n",
      "Validation MSE  0.019538404065390237\n",
      "\n",
      "\n",
      "\n",
      "Train r2_score  88.07772649777152 %\n",
      "Validation r2_score  74.1671459261932 %\n",
      "Test r2_score  68.16647479790612 %\n",
      "\n",
      "\n",
      "\n",
      "Train score  88.07772649777152 %\n",
      "Validation Score  74.1671459261932 %\n",
      "test score:  68.16647479790612 %\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Train MSE \"       , mean_squared_error( y_train_r,Train_pred_roll ))\n",
    "print(\"Validation MSE \"  , mean_squared_error( y_val_r,Validation_pred_roll ))\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "\n",
    "print(\"Train r2_score \"            , r2_score(y_train_r,Train_pred_roll)*100,\"%\")\n",
    "print(\"Validation r2_score \"       , r2_score( y_val_r, Validation_pred_roll)*100,\"%\")\n",
    "print(\"Test r2_score \"             , r2_score(y_test_r , roll_hat)*100,\"%\")\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "print(\"Train score \"                   , roll_fit_models['rfpcap'].score(X_train_r , y_train_r)*100,\"%\")\n",
    "print(\"Validation Score \"              , roll_fit_models['rfpcap'].score(X_val_r, y_val_r)*100,\"%\")\n",
    "print(\"test score: \"                   , roll_fit_models ['rfpcap'].score(X_test_r, y_test_r)*100,\"%\")\n",
    " \n",
    "print(\"\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9d33e486",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Writing results To a pickle file\n",
    "\n",
    "with open(\"C:\\\\Users\\\\SIDDIK\\#ITI_Laptop\\#ITI_PC\\ML 1\\PC\\ML 1\\Project\\content/\"+'roll_model.pkl', 'wb') as f:\n",
    "    pickle.dump(roll_fit_models ['rfpcap'], f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb94745d",
   "metadata": {},
   "source": [
    "### PITCH  Data (Training, Error & Score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c7888631",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Creating a pipleline for different ML models to Test\n",
    "\n",
    "pipelines = {\n",
    "#     'lr_pca':make_pipeline(StandardScaler(),PCA(n_components=0.99), LinearRegression()),\n",
    "    'rf_pca':make_pipeline(MinMaxScaler(),PCA(n_components=0.99), RandomForestRegressor())\n",
    "#     ,'lr_wpca':make_pipeline(PCA(n_components=0.99),LinearRegression()),\n",
    "#     'rf_wpca':make_pipeline(PCA(n_components=0.99),RandomForestRegressor()),\n",
    "#     'DT'    :make_pipeline(DecisionTreeRegressor()),\n",
    "#     'DTpca' :make_pipeline(PCA(n_components=0.99),DecisionTreeRegressor()),\n",
    "#     'rfpcap' :make_pipeline(   RandomForestRegressor(n_estimators=30, n_jobs=-1))\n",
    "# \n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8a1e4efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pitch_fit_models = {}\n",
    "for algo, pipeline in pipelines.items():\n",
    "    model = pipeline.fit(X_train_p, y_train_p)\n",
    "    pitch_fit_models[algo] = model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5dd5fc18",
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_pred_pitch     = pitch_fit_models['rf_pca'].predict(X_train_p)\n",
    "Validation_pred_pitch = pitch_fit_models['rf_pca'].predict(X_val_p)\n",
    "pitch_hat=pitch_fit_models['rf_pca'].predict(X_test_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8aca3333",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train MSE  0.04856987616154295\n",
      "Validation MSE  0.020881111965834184\n",
      "\n",
      "\n",
      "\n",
      "Train r2_score  86.55555403321857 %\n",
      "Validation r2_score  67.41803601757243 %\n",
      "Test r2_score  61.749973833238194 %\n",
      "\n",
      "\n",
      "\n",
      "Train score  86.55555403321857 %\n",
      "Validation Score  67.41803601757243 %\n",
      "test score:  61.749973833238194 %\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#### print(\"Train MSE \"       , mean_squared_error( y_train_y,Train_pred_yaw ))\n",
    "print(\"Train MSE \"       , mean_squared_error( y_train_p,Train_pred_pitch ))\n",
    "print(\"Validation MSE \"  , mean_squared_error( y_val_p,Validation_pred_pitch ))\n",
    "\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "print(\"Train r2_score \"            , r2_score(y_train_p,Train_pred_pitch)*100,\"%\")\n",
    "print(\"Validation r2_score \"       , r2_score( y_val_p, Validation_pred_pitch)*100,\"%\")\n",
    "print(\"Test r2_score \"             , r2_score(y_test_p , pitch_hat)*100,\"%\")\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "\n",
    "print(\"Train score \"                   , pitch_fit_models['rf_pca'].score(X_train_p , y_train_p)*100,\"%\")\n",
    "print(\"Validation Score \"              , pitch_fit_models['rf_pca'].score(X_val_p, y_val_p)*100,\"%\")\n",
    "print(\"test score: \"                   ,pitch_fit_models ['rf_pca'].score(X_test_p, y_test_p)*100,\"%\")\n",
    "print(\"\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "de788ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Writing results To a pickle file\n",
    "\n",
    "with open(\"C:\\\\Users\\\\SIDDIK\\#ITI_Laptop\\#ITI_PC\\ML 1\\PC\\ML 1\\Project\\content/\"+'pitch_model.pkl', 'wb') as f:\n",
    "    pickle.dump(pitch_fit_models ['rf_pca'], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ba5b89bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_axis(img, pitch,yaw,roll, tdx=None, tdy=None, size = 100):\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d420266",
   "metadata": {},
   "source": [
    "## Reading Trained Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "39fff5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"C:\\\\Users\\\\SIDDIK\\#ITI_Laptop\\#ITI_PC\\ML 1\\PC\\ML 1\\Project\\content/\"+'yaw_model.pkl', 'rb') as f:\n",
    "    yaw_model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1b44b248",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"C:\\\\Users\\\\SIDDIK\\#ITI_Laptop\\#ITI_PC\\ML 1\\PC\\ML 1\\Project\\content/\"+'pitch_model.pkl', 'rb') as f:\n",
    "    pitch_model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2c0aef49",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"C:\\\\Users\\\\SIDDIK\\#ITI_Laptop\\#ITI_PC\\ML 1\\PC\\ML 1\\Project\\content/\"+'roll_model.pkl', 'rb') as f:\n",
    "    roll_model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caecca74-cf62-4748-930c-8dc47a03b82a",
   "metadata": {},
   "source": [
    "## Live Camera and Draw axises on face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4f0fe11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Initiate holistic model\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        # Recolor Feed\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False        \n",
    "        \n",
    "        # Make Detections\n",
    "        results = holistic.process(image)\n",
    "        # print(results.face_landmarks)\n",
    "        \n",
    "        # face_landmarks, pose_landmarks, left_hand_landmarks, right_hand_landmarks\n",
    "        \n",
    "        # Recolor image back to BGR for rendering\n",
    "        image.flags.writeable = True   \n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        image_height, image_width, _ = image.shape\n",
    "\n",
    "        # 1. Draw face landmarks on your face \n",
    "        \n",
    "        # mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACEMESH_TESSELATION, \n",
    "        #                          mp_drawing.DrawingSpec(color=(80,110,10), thickness=1, circle_radius=1),\n",
    "        #                          mp_drawing.DrawingSpec(color=(80,256,121), thickness=1, circle_radius=1)\n",
    "        #                          )\n",
    "        \n",
    "        \n",
    "        try:\n",
    "           \n",
    "            face = results.face_landmarks.landmark\n",
    "            NoseX = results.pose_landmarks.landmark[mp_holistic.PoseLandmark.NOSE].x * image_width\n",
    "            NoseY=results.pose_landmarks.landmark[mp_holistic.PoseLandmark.NOSE].y   *image_height\n",
    "            LfeoX = results.pose_landmarks.landmark[mp_holistic.PoseLandmark.LEFT_EYE_OUTER].x *image_width\n",
    "            LfeoY = results.pose_landmarks.landmark[mp_holistic.PoseLandmark.LEFT_EYE_OUTER].y* image_height\n",
    "            \n",
    "            dist = math.dist([NoseX, NoseY], [LfeoX, LfeoY])\n",
    "            face_row = list(np.array([[   ((landmark.x *image_width)-NoseX)/dist, \n",
    "                                            ((landmark.y*image_height)-NoseY)/dist] for landmark in face]).reshape(1, -1))\n",
    "            \n",
    "#             print(face_row)\n",
    "            pitch = pitch_model.predict(face_row)\n",
    "            yaw = yaw_model.predict(face_row)\n",
    "            roll = roll_model.predict(face_row)\n",
    "            \n",
    "\n",
    "#             cv2_imshow(draw_axis(image,pitch,yaw,roll))\n",
    "            yaw = -yaw\n",
    "            tdx = NoseX\n",
    "            tdy = NoseY\n",
    "            size=100\n",
    "    # X-Axis pointing to right. drawn in red\n",
    "            x1 = size * (cos(yaw) * cos(roll)) + tdx\n",
    "            y1 = size * (cos(pitch) * sin(roll) + cos(roll) * sin(pitch) * sin(yaw)) + tdy\n",
    "\n",
    "    # Y-Axis | drawn in green\n",
    "            x2 = size * (-cos(yaw) * sin(roll)) + tdx\n",
    "            y2 = size * (cos(pitch) * cos(roll) - sin(pitch) * sin(yaw) * sin(roll)) + tdy\n",
    "\n",
    "    # Z-Axis (out of the screen) drawn in blue\n",
    "            x3 = size * (sin(yaw)) + tdx\n",
    "            y3 = size * (-cos(yaw) * sin(pitch)) + tdy\n",
    "            cv2.line(image, (int(tdx), int(tdy)), (int(x1),int(y1)),(0,0,255),3)\n",
    "            cv2.line(image, (int(tdx), int(tdy)), (int(x2),int(y2)),(0,255,0),3)\n",
    "            cv2.line(image, (int(tdx), int(tdy)), (int(x3),int(y3)),(255,0,0),2)\n",
    "\n",
    "            \n",
    "        except:\n",
    "            pass\n",
    "\n",
    "\n",
    "            \n",
    "        cv2.imshow('Raw Webcam Feed', image)\n",
    "\n",
    "### Press q to stop camera Capturing\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Test1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
